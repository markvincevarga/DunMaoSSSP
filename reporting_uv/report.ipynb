{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ef97d517ace249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "benchmark_path = Path(\"../target/criterion\")\n",
    "maps_paths = list(map(lambda p: benchmark_path / Path(p), filter(lambda n: n != \"report\", os.listdir(benchmark_path))))\n",
    "os.listdir()\n",
    "\n",
    "methods = [\"fast_sssp_sequential\", \"dijkstra\", \"dijkstra_fibonacci\"]\n",
    "\n",
    "\n",
    "# {map_name: {method_name: {metric_name: value}}}\n",
    "def load_json(filename: Path) -> dict:\n",
    "    with open(filename) as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "data = {\n",
    "    m.name: {method: load_json(m / Path(method) / Path(\"new/estimates.json\")) for method in methods}\n",
    "    for m in maps_paths\n",
    "}\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0a675831e2f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "pairs = [\n",
    "    (\"jan_mayen\", 500),\n",
    "    (\"gibraltar\", 500),\n",
    "    (\"monaco\", 500),\n",
    "    (\"san_marino\", 200),\n",
    "    (\"andorra\", 150),\n",
    "    (\"gotland\", 150),\n",
    "    (\"malta\", 150),\n",
    "    (\"reykjavik\", 150),\n",
    "    (\"budapest\", 150),\n",
    "    (\"luxembourg\", 100),\n",
    "    (\"haiti\", 100),\n",
    "    (\"iceland\", 100),\n",
    "    (\"stockholm\", 100),\n",
    "    (\"missisippi\", 100),\n",
    "]\n",
    "\n",
    "\n",
    "def normalize_recursive(item: Any, pair_count: int) -> Any:\n",
    "    if isinstance(item, dict):\n",
    "        return {k: (normalize_recursive(v, pair_count) if k != \"confidence_level\" else v) for k, v in item.items()}\n",
    "    if isinstance(item, list):\n",
    "        return [normalize_recursive(i, pair_count) for i in item]\n",
    "    if isinstance(item, (float, int)):\n",
    "        return item / pair_count\n",
    "    return item\n",
    "\n",
    "\n",
    "normalized_data = {area: normalize_recursive(data[area + \".osm\"], pair_count) for area, pair_count in pairs}\n",
    "normalized_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2688de262e630950",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Fibonacci run times\")\n",
    "for area, v in normalized_data.items():\n",
    "    method_data = v[\"dijkstra_fibonacci\"]\n",
    "    print(f\"{area} \\t  \\t {method_data['mean']['point_estimate']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdfe837645cba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = {\n",
    "    \"jan_mayen\": {\"edges\": 29_786, \"nodes\": 13_230},\n",
    "    \"monaco\": {\"edges\": 72_318, \"nodes\": 32_492},\n",
    "    \"gibraltar\": {\"edges\": 100_284, \"nodes\": 44_639},\n",
    "    \"san_marino\": {\"edges\": 341_976, \"nodes\": 154_249},\n",
    "    \"andorra\": {\"edges\": 1043_844, \"nodes\": 449_273},\n",
    "    \"gotland\": {\"edges\": 1634_818, \"nodes\": 725_852},\n",
    "    \"malta\": {\"edges\": 1_818_642, \"nodes\": 734_962},\n",
    "\n",
    "    \"reykjavik\": {\"edges\": 2_241_396, \"nodes\": 1_051_160},\n",
    "    \"budapest\": {\"edges\": 5_187_404, \"nodes\": 2_443_154},\n",
    "    \"luxembourg\": {\"edges\": 10_664_130, \"nodes\": 3_916_210},\n",
    "    \"haiti\": {\"edges\": 17_186_498, \"nodes\": 8_497_106},\n",
    "\n",
    "    \"iceland\": {\"edges\": 21_055_604, \"nodes\": 10_350_896},\n",
    "    \"missisippi\": {\"edges\": 21_372_374, \"nodes\": 10_464_418},\n",
    "    \"stockholm\": {\"edges\": 16_459_816, \"nodes\": 73_07_104},\n",
    "}\n",
    "normalized_data_with_graph = {\n",
    "    area: {\"methods\": normalized_data[area], \"graph\": graph_data[area]} for area, v in normalized_data.items()\n",
    "}\n",
    "normalized_data_with_graph[\"jan_mayen\"][\"graph\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667622f85e85ec62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73873d4545e04eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: restrict the amount of data\n",
    "\n",
    "# Split the data by graph size (nodes); <= 1_000_000 nodes, between 1_000_000 and 10_000_000 nodes, and > 10_000_000 nodes\n",
    "small_max = 1_000_000\n",
    "medium_max = 11_000_000\n",
    "\n",
    "split_graph_data = {\n",
    "    'small': {k: v for k, v in normalized_data_with_graph.items() if v[\"graph\"][\"nodes\"] <= small_max},\n",
    "    'medium': {k: v for k, v in normalized_data_with_graph.items() if small_max < v[\"graph\"][\"nodes\"] <= medium_max},\n",
    "    'large': {k: v for k, v in normalized_data_with_graph.items() if v[\"graph\"][\"nodes\"] > medium_max},\n",
    "}\n",
    "\n",
    "filtered_methods = [m for m in methods if m != \"dijkstra_fibonacci\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b078e78a26a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6881841017ab84e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\"dijkstra\": \"C0\", \"dijkstra_fibonacci\": \"C1\", \"fast_sssp_sequential\": \"C2\"}\n",
    "small_data = split_graph_data['small']\n",
    "sm_data = {**small_data, **split_graph_data['medium']}\n",
    "algo_labels = {\"dijkstra\": \"Dijkstra (Binary Heap)\", \"dijkstra_fibonacci\": \"Dijkstra (Fibonacci Heap)\",\n",
    "               \"fast_sssp_sequential\": \"Duan et al.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb81fe0faaae634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LaTeX table from normalized_data_with_graph\n",
    "table_data = []\n",
    "for area, data in normalized_data_with_graph.items():\n",
    "    row = {'Area': area.replace('_', ' ').title()}\n",
    "\n",
    "    for method in methods:\n",
    "        method_data = data['methods'][method]\n",
    "        mean = method_data['mean']['point_estimate']\n",
    "        std_err = method_data['mean']['standard_error']\n",
    "\n",
    "        # Use the labels dictionary for method names\n",
    "        method_label = algo_labels.get(method, method)\n",
    "        row[f'{method_label}_Mean'] = f'{mean:.2e}'\n",
    "        row[f'{method_label}_StdErr'] = f'{std_err:.2e}'\n",
    "\n",
    "    table_data.append(row)\n",
    "\n",
    "header_lines = []\n",
    "header_lines.append(\"\\\\begin{tabularx}{\\\\textwidth}{|l|\" + \"cc|\" * len(methods) + \"}\")\n",
    "header_lines.append(\"\\\\hline\")\n",
    "first_row = \"Area\"\n",
    "for method in methods:\n",
    "    method_label = algo_labels.get(method, method)\n",
    "    first_row += f\" & \\\\multicolumn{{2}}{{c|}}{{{method_label}}}\"\n",
    "first_row += \" \\\\\\\\\"\n",
    "header_lines.append(first_row)\n",
    "\n",
    "second_row = \"\"\n",
    "for i, method in enumerate(methods):\n",
    "    if i == 0:\n",
    "        second_row += \" & Mean & Standard Error\"\n",
    "    else:\n",
    "        second_row += \" & Mean & Standard Error\"\n",
    "second_row += \" \\\\\\\\\"\n",
    "\n",
    "header_lines.append(\"\\\\hline\")\n",
    "header_lines.append(second_row)\n",
    "header_lines.append(\"\\\\hline\")\n",
    "\n",
    "# Data rows\n",
    "for area, data in normalized_data_with_graph.items():\n",
    "    data_row = area.replace('_', ' ').title()\n",
    "    for method in methods:\n",
    "        method_data = data['methods'][method]\n",
    "        mean = method_data['mean']['point_estimate']\n",
    "        std_err = method_data['mean']['standard_error']\n",
    "        data_row += f\" & {mean:.2e} & {std_err:.2e}\"\n",
    "    data_row += \" \\\\\\\\\"\n",
    "    header_lines.append(data_row)\n",
    "\n",
    "header_lines.append(\"\\\\hline\")\n",
    "header_lines.append(\"\\\\end{tabularx}\")\n",
    "\n",
    "# Print the LaTeX table\n",
    "latex_output = \"\\n\".join(header_lines)\n",
    "print(latex_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29702e1f145580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import ticker\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f90789e7e4cf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_data = sm_data\n",
    "#  Define missing functions and variables\n",
    "def calculate_r_squared(y_actual, y_predicted):\n",
    "    ss_res = np.sum((y_actual - y_predicted) ** 2)\n",
    "    ss_tot = np.sum((y_actual - np.mean(y_actual)) ** 2)\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n",
    "# Get average degree from graph data\n",
    "avg_degree = np.mean([graph_data[area.replace('_', ' ').lower().replace(' ', '_')][\"edges\"] / graph_data[area.replace('_', ' ').lower().replace(' ', '_')][\"nodes\"] for area in sm_data.keys() if area.replace('_', ' ').lower().replace(' ', '_') in graph_data])\n",
    "\n",
    "# Define curve fitting functions\n",
    "mp = {\n",
    "    'dijkstra': lambda v, a, b: a * (avg_degree * v + v) * np.log(v) + b,\n",
    "    'dijkstra_fibonacci': lambda v, a, b: a * ((avg_degree * v) + v * np.log(v)) + b,\n",
    "    'fast_sssp_sequential': lambda v, a, b: a * ((avg_degree * v) * np.log(v) ** 2 / 3) + b,\n",
    "}\n",
    "\n",
    "def sign_of(s: float) -> str:\n",
    "    return \"+\" if s >= 0 else \"-\"\n",
    "\n",
    "# Define formula formatting functions\n",
    "formulas = {\n",
    "    'dijkstra': lambda a, b: f'{a:.2f} * ({avg_degree:.2f} * v + v) * log(v) {sign_of(b)} {np.abs(b):,.2f}',\n",
    "    'dijkstra_fibonacci': lambda a, b: f'{a:.2f} * ({avg_degree:.2f} * v + v * log(v)) {sign_of(b)} {np.abs(b):,.2f}',\n",
    "    'fast_sssp_sequential': lambda a, b: f'{a:.2f} * ({avg_degree:.2f} * v * log(v)^(2/3)) {sign_of(b)} {np.abs(b):,.2f}',\n",
    "}\n",
    "\n",
    "\n",
    "# Create combined plot with dijkstra and fast_sssp_sequential\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for method in filtered_methods:\n",
    "    x = np.array([normalized_data_with_graph[a][\"graph\"][\"nodes\"] for a in this_data])\n",
    "    y = np.array([normalized_data_with_graph[a][\"methods\"][method][\"mean\"][\"point_estimate\"] for a in\n",
    "                  this_data])\n",
    "    z = mp[method]\n",
    "\n",
    "    fitted_params, pcov = curve_fit(z, x, y)\n",
    "\n",
    "    # Generate points for the trendline\n",
    "    x_sorted = np.sort(x)\n",
    "    y_fitted = z(x_sorted, *fitted_params)\n",
    "\n",
    "    # Calculate R-squared for the fit\n",
    "    y_pred = z(x, *fitted_params)\n",
    "    r_squared = calculate_r_squared(y, y_pred)\n",
    "\n",
    "    formula = formulas[method](fitted_params[0], fitted_params[1])\n",
    "    \n",
    "    # Plot trendline and scatter for each method\n",
    "    plt.plot(x_sorted, y_fitted,\n",
    "             label=f\"{algo_labels[method]} Trendline: {formula}, R² = {r_squared:.3f}\",\n",
    "             c=colors.get(method, None), linestyle='-')\n",
    "    plt.scatter(x, y, label=algo_labels[method], s=30, alpha=0.8, c=colors.get(method, None))\n",
    "\n",
    "plt.xlabel(\"Number of nodes\")\n",
    "plt.ylabel(\"Mean time (s)\")\n",
    "\n",
    "plt.gca().xaxis.set_major_formatter(\n",
    "    ticker.FuncFormatter(\n",
    "        lambda x, p: f'{x / 1e6:.0f}M' if x >= 1e6 else f'{x / 1e3:.0f}k' if x >= 1e3 else f'{x:.0f}'))\n",
    "plt.gca().yaxis.set_major_formatter(\n",
    "    ticker.FuncFormatter(\n",
    "        lambda x, p: f'{x / 1e6:.0f}' if x >= 1e6 else f'{x / 1e3:.0f}' if x >= 1e3 else f'{x:.0f}'))\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "Path(\"graphs\").mkdir(exist_ok=True)\n",
    "plt.savefig(\"graphs/combined_dijkstra_fast_sssp.png\")\n",
    "plt.show()\n",
    "\n",
    "# Remove the first combined graph - keep only the second graph with all three algorithms\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for method in methods:  # Use all methods including fibonacci\n",
    "    x = np.array([normalized_data_with_graph[a][\"graph\"][\"nodes\"] for a in this_data])\n",
    "    y = np.array([normalized_data_with_graph[a][\"methods\"][method][\"mean\"][\"point_estimate\"] for a in\n",
    "                  this_data])\n",
    "    z = mp[method]\n",
    "\n",
    "    fitted_params, pcov = curve_fit(z, x, y)\n",
    "\n",
    "    # Generate points for the trendline\n",
    "    x_sorted = np.sort(x)\n",
    "    y_fitted = z(x_sorted, *fitted_params)\n",
    "\n",
    "    # Calculate R-squared for the fit\n",
    "    y_pred = z(x, *fitted_params)\n",
    "    r_squared = calculate_r_squared(y, y_pred)\n",
    "\n",
    "    formula = formulas[method](fitted_params[0], fitted_params[1])\n",
    "    \n",
    "    # Plot trendline and scatter for each method\n",
    "    plt.plot(x_sorted, y_fitted,\n",
    "             label=f\"{algo_labels[method]} Trendline: {formula}, R² = {r_squared:.3f}\",\n",
    "             c=colors.get(method, None), linestyle='-')\n",
    "    plt.scatter(x, y, label=algo_labels[method], s=30, alpha=0.8, c=colors.get(method, None))\n",
    "\n",
    "plt.xlabel(\"Number of nodes\")\n",
    "plt.ylabel(\"Mean time (s)\")\n",
    "\n",
    "plt.gca().xaxis.set_major_formatter(\n",
    "    ticker.FuncFormatter(\n",
    "        lambda x, p: f'{x / 1e6:.0f}M' if x >= 1e6 else f'{x / 1e3:.0f}k' if x >= 1e3 else f'{x:.0f}'))\n",
    "plt.gca().yaxis.set_major_formatter(\n",
    "    ticker.FuncFormatter(\n",
    "        lambda x, p: f'{x / 1e6:.0f}' if x >= 1e6 else f'{x / 1e3:.0f}' if x >= 1e3 else f'{x:.0f}'))\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/mean_times_trendlines.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6644962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New version of the above with enlarged labels\n",
    "def calculate_r_squared(y_actual, y_predicted):\n",
    "    ss_res = np.sum((y_actual - y_predicted) ** 2)\n",
    "    ss_tot = np.sum((y_actual - np.mean(y_actual)) ** 2)\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n",
    "# Get average degree from graph data\n",
    "avg_degree = np.mean([graph_data[area.replace('_', ' ').lower().replace(' ', '_')][\"edges\"] / graph_data[area.replace('_', ' ').lower().replace(' ', '_')][\"nodes\"] for area in sm_data.keys() if area.replace('_', ' ').lower().replace(' ', '_') in graph_data])\n",
    "\n",
    "# Define curve fitting functions\n",
    "mp = {\n",
    "    'dijkstra': lambda v, a, b: a * (avg_degree * v + v) * np.log(v) + b,\n",
    "    'dijkstra_fibonacci': lambda v, a, b: a * ((avg_degree * v) + v * np.log(v)) + b,\n",
    "    'fast_sssp_sequential': lambda v, a, b: a * ((avg_degree * v) * np.log(v) ** 2 / 3) + b,\n",
    "}\n",
    "\n",
    "def sign_of(s: float) -> str:\n",
    "    return \"+\" if s >= 0 else \"-\"\n",
    "\n",
    "# Define formula formatting functions\n",
    "formulas = {\n",
    "    'dijkstra': lambda a, b: f'{a:.2f} * ({avg_degree:.2f} * v + v) * log(v) {sign_of(b)} {np.abs(b):,.2f}',\n",
    "    'dijkstra_fibonacci': lambda a, b: f'{a:.2f} * ({avg_degree:.2f} * v + v * log(v)) {sign_of(b)} {np.abs(b):,.2f}',\n",
    "    'fast_sssp_sequential': lambda a, b: f'{a:.2f} * ({avg_degree:.2f} * v * log(v)^(2/3)) {sign_of(b)} {np.abs(b):,.2f}',\n",
    "}\n",
    "\n",
    "# Create graph with all three algorithms\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for method in methods:  # Use all methods including fibonacci\n",
    "    x = np.array([normalized_data_with_graph[a][\"graph\"][\"nodes\"] for a in this_data])\n",
    "    y = np.array([normalized_data_with_graph[a][\"methods\"][method][\"mean\"][\"point_estimate\"] for a in\n",
    "                  this_data])\n",
    "    z = mp[method]\n",
    "\n",
    "    fitted_params, pcov = curve_fit(z, x, y)\n",
    "\n",
    "    # Generate points for the trendline\n",
    "    x_sorted = np.sort(x)\n",
    "    y_fitted = z(x_sorted, *fitted_params)\n",
    "\n",
    "    # Calculate R-squared for the fit\n",
    "    y_pred = z(x, *fitted_params)\n",
    "    r_squared = calculate_r_squared(y, y_pred)\n",
    "\n",
    "    formula = formulas[method](fitted_params[0], fitted_params[1])\n",
    "    \n",
    "    # Plot trendline and scatter for each method\n",
    "    plt.plot(x_sorted, y_fitted,\n",
    "             label=f\"{algo_labels[method]} Trendline (R² = {r_squared:.3f})\",\n",
    "             c=colors.get(method, None), linestyle='-')\n",
    "    plt.scatter(x, y, label=algo_labels[method], s=30, alpha=0.8, c=colors.get(method, None))\n",
    "\n",
    "plt.xlabel(\"Number of nodes\")\n",
    "plt.ylabel(\"Mean time (s)\")\n",
    "\n",
    "plt.gca().xaxis.set_major_formatter(\n",
    "    ticker.FuncFormatter(\n",
    "        lambda x, p: f'{x / 1e6:.0f}M' if x >= 1e6 else f'{x / 1e3:.0f}k' if x >= 1e3 else f'{x:.0f}'))\n",
    "plt.gca().yaxis.set_major_formatter(\n",
    "    ticker.FuncFormatter(\n",
    "        lambda x, p: f'{x / 1e6:.0f}' if x >= 1e6 else f'{x / 1e3:.0f}' if x >= 1e3 else f'{x:.0f}'))\n",
    "\n",
    "plt.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "Path(\"graphs\").mkdir(exist_ok=True)\n",
    "plt.savefig(\"graphs/mean_times_trendlines.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd237e0ac623c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "areas = []\n",
    "speedups = []\n",
    "labels = []\n",
    "\n",
    "for area, data in normalized_data_with_graph.items():\n",
    "    dijkstra_time = data[\"methods\"][\"dijkstra\"][\"mean\"][\"point_estimate\"]\n",
    "    fast_sssp_time = data[\"methods\"][\"fast_sssp_sequential\"][\"mean\"][\"point_estimate\"]\n",
    "    speedup = dijkstra_time / fast_sssp_time\n",
    "\n",
    "    # Format node count in human readable format\n",
    "    nodes = data[\"graph\"][\"nodes\"]\n",
    "    if nodes >= 1_000_000:\n",
    "        node_label = f\"{nodes / 1_000_000:.1f}M\"\n",
    "    elif nodes >= 1_000:\n",
    "        node_label = f\"{nodes / 1_000:.0f}k\"\n",
    "    else:\n",
    "        node_label = str(nodes)\n",
    "\n",
    "    areas.append(area)\n",
    "    speedups.append(speedup)\n",
    "    labels.append(f\"{area.replace('_', ' ').title()} ({node_label} nodes)\")\n",
    "\n",
    "# Sort by number of nodes for better visualization\n",
    "sorted_indices = sorted(range(len(areas)), key=lambda i: normalized_data_with_graph[areas[i]][\"graph\"][\"nodes\"])\n",
    "sorted_areas = [areas[i] for i in sorted_indices]\n",
    "sorted_speedups = [speedups[i] for i in sorted_indices]\n",
    "sorted_labels = [labels[i] for i in sorted_indices]\n",
    "\n",
    "# Create the column graph\n",
    "plt.figure(figsize=(14, 8))\n",
    "bars = plt.bar(range(len(sorted_areas)), sorted_speedups, color=['green' if s > 1 else 'red' for s in sorted_speedups])\n",
    "\n",
    "# Add speedup numbers above the bars\n",
    "for i, (bar, speedup) in enumerate(zip(bars, sorted_speedups)):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2., height + 0.1,\n",
    "             f'{speedup:.2f}x', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Add a horizontal line at y=1 to show no speedup/slowdown\n",
    "plt.axhline(y=1, color='black', linestyle='--', alpha=0.7, label='No speedup/slowdown')\n",
    "\n",
    "plt.xlabel('Area')\n",
    "plt.ylabel('Speedup (dijkstra / fast_sssp_sequential)')\n",
    "plt.xticks(range(len(sorted_areas)), sorted_labels, rotation=30, ha='right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "average_speedup = sum(sorted_speedups) / len(sorted_speedups)\n",
    "print(f\"\\nAverage speedup across all areas: {average_speedup:.2f}x\")\n",
    "# Save the speedup graph\n",
    "Path(\"graphs\").mkdir(exist_ok=True)\n",
    "plt.savefig(\"graphs/speedup_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "speedups_excluding_first_3 = sorted_speedups[3:]\n",
    "average_speedup_excluding_first_3 = sum(speedups_excluding_first_3) / len(speedups_excluding_first_3)\n",
    "print(f\"Average speedup excluding for areas larger than 50k Nodes: {average_speedup_excluding_first_3:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a79dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy of graph above with larger figure size and fonts\n",
    "areas = []\n",
    "speedups = []\n",
    "labels = []\n",
    "\n",
    "for area, data in normalized_data_with_graph.items():\n",
    "    dijkstra_time = data[\"methods\"][\"dijkstra\"][\"mean\"][\"point_estimate\"]\n",
    "    fast_sssp_time = data[\"methods\"][\"fast_sssp_sequential\"][\"mean\"][\"point_estimate\"]\n",
    "    speedup = dijkstra_time / fast_sssp_time\n",
    "\n",
    "    # Format node count in human readable format\n",
    "    nodes = data[\"graph\"][\"nodes\"]\n",
    "    if nodes >= 1_000_000:\n",
    "        node_label = f\"{nodes / 1_000_000:.1f}M\"\n",
    "    elif nodes >= 1_000:\n",
    "        node_label = f\"{nodes / 1_000:.0f}k\"\n",
    "    else:\n",
    "        node_label = str(nodes)\n",
    "\n",
    "    areas.append(area)\n",
    "    speedups.append(speedup)\n",
    "    labels.append(f\"{area.replace('_', ' ').title()} ({node_label} nodes)\")\n",
    "\n",
    "# Sort by number of nodes for better visualization\n",
    "sorted_indices = sorted(range(len(areas)), key=lambda i: normalized_data_with_graph[areas[i]][\"graph\"][\"nodes\"])\n",
    "sorted_areas = [areas[i] for i in sorted_indices]\n",
    "sorted_speedups = [speedups[i] for i in sorted_indices]\n",
    "sorted_labels = [labels[i] for i in sorted_indices]\n",
    "\n",
    "# Create the column graph with larger figure size and fonts\n",
    "plt.figure(figsize=(16, 10))\n",
    "bars = plt.bar(range(len(sorted_areas)), sorted_speedups, color=['green' if s > 1 else 'red' for s in sorted_speedups])\n",
    "\n",
    "# Add speedup numbers above the bars with larger font\n",
    "for i, (bar, speedup) in enumerate(zip(bars, sorted_speedups)):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2., height + 0.1,\n",
    "             f'{speedup:.2f}x', ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add a horizontal line at y=1 to show no speedup/slowdown\n",
    "plt.axhline(y=1, color='black', linestyle='--', alpha=0.7, label='No speedup/slowdown')\n",
    "\n",
    "plt.xlabel('Area', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Speedup (dijkstra / fast_sssp_sequential)', fontsize=16, fontweight='bold')\n",
    "plt.xticks(range(len(sorted_areas)), sorted_labels, rotation=30, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "# Save the speedup graph\n",
    "Path(\"graphs\").mkdir(exist_ok=True)\n",
    "plt.savefig(\"graphs/speedup_comparison_large.png\", dpi=300, bbox_inches='tight')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "average_speedup = sum(sorted_speedups) / len(sorted_speedups)\n",
    "print(f\"\\nAverage speedup across all areas: {average_speedup:.2f}x\")\n",
    "\n",
    "speedups_excluding_first_3 = sorted_speedups[3:]\n",
    "average_speedup_excluding_first_3 = sum(speedups_excluding_first_3) / len(speedups_excluding_first_3)\n",
    "print(f\"Average speedup excluding for areas larger than 50k Nodes: {average_speedup_excluding_first_3:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96684768e0a422f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graph metrics\n",
    "metric_files = list(Path(\"graph_metrics\").iterdir())\n",
    "\n",
    "# Load graph metrics from each file\n",
    "graph_metrics = {}\n",
    "for file_path in metric_files:\n",
    "    # Extract map name from file name (remove _metrics.json)\n",
    "    map_name = file_path.stem.replace('_metrics', '')\n",
    "    \n",
    "    # Load JSON data from file\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            graph_metrics[map_name] = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "\n",
    "graph_metrics\n",
    "\n",
    "# Create a function to process distribution data\n",
    "def fix_distribution_data(metrics_data):\n",
    "    for map_name, map_data in metrics_data.items():\n",
    "        # Check if 'degrees' exists and contains 'distribution'\n",
    "        if 'degrees' in map_data and 'distribution' in map_data['degrees']:\n",
    "            distribution = map_data['degrees']['distribution']\n",
    "            \n",
    "            # Convert string keys to int and sort\n",
    "            if isinstance(distribution, dict):\n",
    "                new_distribution = {}\n",
    "                # Convert string keys to integers\n",
    "                for key, value in distribution.items():\n",
    "                    try:\n",
    "                        new_distribution[int(key)] = value\n",
    "                    except ValueError:\n",
    "                        # Keep as is if not convertible to int\n",
    "                        new_distribution[key] = value\n",
    "                \n",
    "                # Create a sorted dictionary\n",
    "                sorted_distribution = {k: new_distribution[k] for k in sorted(new_distribution.keys())}\n",
    "                map_data['degrees']['distribution'] = sorted_distribution\n",
    "    \n",
    "    return metrics_data\n",
    "\n",
    "# Apply the fix to the loaded graph metrics\n",
    "graph_metrics = fix_distribution_data(graph_metrics)\n",
    "\n",
    "graph_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eaba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LaTeX table with graph metrics information\n",
    "\n",
    "# Prepare data for the table\n",
    "table_data = []\n",
    "\n",
    "# Keys we want to extract from each graph\n",
    "metrics_to_extract = [\n",
    "    ('graph_info.vertices', 'Vertices'),\n",
    "    ('graph_info.edges', 'Edges'),\n",
    "    ('degrees.average', 'Avg Degree'),\n",
    "    ('degrees.max', 'Max Degree'),\n",
    "    ('diameter.value', 'Diameter'),\n",
    "    ('clustering.average', 'Clustering Coef')\n",
    "]\n",
    "\n",
    "# Process data for each map in graph_metrics\n",
    "for map_name in graph_metrics.keys():\n",
    "    row_data = {'Map': map_name.replace('_', ' ').title()}\n",
    "    \n",
    "    metrics = graph_metrics[map_name]\n",
    "    \n",
    "    # Extract nested values\n",
    "    for key_path, label in metrics_to_extract:\n",
    "        parts = key_path.split('.')\n",
    "        value = metrics\n",
    "        try:\n",
    "            for part in parts:\n",
    "                value = value[part]\n",
    "            \n",
    "            # Format the value based on its type\n",
    "            if isinstance(value, (int)):\n",
    "                row_data[label] = f\"{value:,}\"\n",
    "            elif isinstance(value, float):\n",
    "                row_data[label] = f\"{value:.4f}\"\n",
    "            else:\n",
    "                row_data[label] = str(value)\n",
    "        except (KeyError, TypeError):\n",
    "            row_data[label] = \"N/A\"\n",
    "    \n",
    "    table_data.append(row_data)\n",
    "\n",
    "# Sort the table data by number of vertices (ascending)\n",
    "table_data.sort(key=lambda x: int(x['Vertices'].replace(',', '')))\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_lines = [\n",
    "    \"\\\\begin{table}[htbp]\",\n",
    "    \"\\\\centering\",\n",
    "    \"\\\\caption{Graph Metrics Summary}\",\n",
    "    \"\\\\begin{tabular}{|l|r|r|r|r|r|p|}\",  # r for right-alignment of numeric columns\n",
    "    \"\\\\hline\",\n",
    "    \"\\\\textbf{Map} & \\\\textbf{Vertices} & \\\\textbf{Edges} & \\\\textbf{Avg Degree} & \\\\textbf{Max Degree} & \\\\textbf{Diameter} & \\\\textbf{Network Clustering Coef} \\\\\\\\\",\n",
    "    \"\\\\hline\"\n",
    "]\n",
    "\n",
    "# Add data rows\n",
    "for row in table_data:\n",
    "    latex_lines.append(f\"{row['Map']} & {row['Vertices']} & {row['Edges']} & {row['Avg Degree']} & {row['Max Degree']} & {row['Diameter']} & {row['Clustering Coef']} \\\\\\\\\")\n",
    "\n",
    "# Close the table\n",
    "latex_lines.extend([\n",
    "    \"\\\\hline\",\n",
    "    \"\\\\end{tabular}\",\n",
    "    \"\\\\label{tab:graph_metrics}\",\n",
    "    \"\\\\end{table}\"\n",
    "])\n",
    "\n",
    "# Join all lines and print the LaTeX table\n",
    "latex_table = \"\\n\".join(latex_lines)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccc7d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sort maps by node count\n",
    "sorted_maps = sorted(graph_metrics.keys(), \n",
    "                    key=lambda m: graph_metrics[m]['graph_info']['vertices'])\n",
    "\n",
    "# Collect all degree distributions and calculate statistics\n",
    "degree_stats = {}\n",
    "\n",
    "for map_name in sorted_maps:\n",
    "    metrics = graph_metrics[map_name]\n",
    "    \n",
    "    if 'degrees' in metrics and 'distribution' in metrics['degrees']:\n",
    "        distribution = metrics['degrees']['distribution']\n",
    "        total_nodes = metrics['graph_info']['vertices']\n",
    "        \n",
    "        # Group degrees 7 and over together\n",
    "        degree_7_plus_count = 0\n",
    "        degree_7_plus_idx = \"7 to 20\"\n",
    "        \n",
    "        for degree_str, frequency_str in distribution.items():\n",
    "            degree = int(degree_str)\n",
    "            frequency = int(frequency_str)\n",
    "            \n",
    "            if degree >= 7:\n",
    "                degree_7_plus_count += frequency\n",
    "            else:\n",
    "                percentage = (frequency / total_nodes) * 100\n",
    "                \n",
    "                if degree not in degree_stats:\n",
    "                    degree_stats[degree] = []\n",
    "                degree_stats[degree].append(percentage)\n",
    "        \n",
    "        # Add the combined 7+ category\n",
    "        if degree_7_plus_count > 0:\n",
    "            percentage_7_plus = (degree_7_plus_count / total_nodes) * 100\n",
    "            if degree_7_plus_idx not in degree_stats:\n",
    "                degree_stats[degree_7_plus_idx] = []\n",
    "            degree_stats[degree_7_plus_idx].append(percentage_7_plus)\n",
    "\n",
    "# Calculate statistics for each degree\n",
    "degrees = [0, 1, 2, 3, 4, 5, 6, degree_7_plus_idx]  # Fixed order\n",
    "means = []\n",
    "stds = []\n",
    "all_data = []\n",
    "\n",
    "for degree in degrees:\n",
    "    if degree in degree_stats:\n",
    "        data = degree_stats[degree]\n",
    "        means.append(np.mean(data))\n",
    "        stds.append(np.std(data))\n",
    "        all_data.append(data)\n",
    "    else:\n",
    "        means.append(0)\n",
    "        stds.append(0)\n",
    "        all_data.append([])\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create box plot to show distribution, whiskers, and outliers\n",
    "box_data = [degree_stats.get(d, []) for d in degrees]\n",
    "positions = list(range(len(degrees)))\n",
    "\n",
    "bp = plt.boxplot([data for data in box_data if len(data) > 0], \n",
    "                positions=[i for i, data in enumerate(box_data) if len(data) > 0], \n",
    "                widths=0.6, patch_artist=True,\n",
    "                showfliers=True, flierprops={'marker': 'o', 'markersize': 3, 'alpha': 0.6})\n",
    "\n",
    "# Customize box plot appearance\n",
    "for patch in bp['boxes']:\n",
    "    patch.set_facecolor('lightblue')\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "plt.xlabel('Degree (number of connections)')\n",
    "plt.ylabel('Percentage of nodes (%)')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Set x-axis labels\n",
    "plt.xticks(positions, degrees)\n",
    "plt.xlim(-0.5, len(degrees) - 0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"graphs/degree_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"Degree Distribution Statistics Summary:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Degree':<8} {'Mean %':<10} {'Std %':<10} {'Maps':<8} {'Min %':<8} {'Max %':<8}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i, degree in enumerate(degrees):\n",
    "    if degree in degree_stats and len(degree_stats[degree]) > 0:\n",
    "        data = degree_stats[degree]\n",
    "        print(f\"{str(degree):<8} {means[i]:<10.2f} {stds[i]:<10.2f} {len(data):<8d} \"\n",
    "              f\"{min(data):<8.2f} {max(data):<8.2f}\")\n",
    "    else:\n",
    "        print(f\"{str(degree):<8} {'N/A':<10} {'N/A':<10} {'0':<8} {'N/A':<8} {'N/A':<8}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reporting-uv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
